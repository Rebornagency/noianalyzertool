import logging
import json
import traceback
import re
from typing import Dict, Any, List, Optional
from openai import OpenAI

from config import get_openai_api_key

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('ai_insights_gpt')

def generate_insights_with_gpt(comparison_results: Dict[str, Any], property_name: str = "") -> Dict[str, Any]:
    """
    Generate professional real estate accounting insights from DETAILED NOI comparison results using GPT.

    Args:
        comparison_results: Results from calculate_noi_comparisons() using detailed data.
        property_name: Name of the property for the analysis.

    Returns:
        Dictionary with professional insights generated by GPT.
    """
    logger.info(f"Generating detailed insights with GPT for property: {property_name}")

    # Initialize OpenAI client with API key
    api_key = get_openai_api_key()
    if not api_key or len(api_key) < 10: # Basic check
         logger.error("Invalid or missing OpenAI API key. Cannot generate insights.")
         return {
            "summary": "Error: OpenAI API key is not configured correctly.",
            "performance": [],
            "recommendations": []
         }
    logger.info(f"Using OpenAI API key: {'*' * (len(api_key) - 5)}{api_key[-5:]}") # Mask key in logs

    client = OpenAI(api_key=api_key)

    # Format DETAILED comparison results for the prompt
    formatted_results = format_detailed_comparison_results_for_prompt(comparison_results)

    # Create the DETAILED prompt for GPT
    prompt = f"""
    You are a senior real estate financial analyst providing insights on property performance based on detailed Net Operating Income (NOI) variance analysis.

    Property Name: {property_name or "This Property"}

    Analyze the following financial comparison data:
    ---
    {formatted_results}
    ---

    Based *only* on the data provided, please provide:
    1.  **Executive Summary:** A concise overview of the property's financial performance, highlighting the main drivers of NOI changes compared to budget and prior periods. Mention key metrics like EGI, Vacancy, and OpEx trends.
    2.  **Key Performance Insights (3-5 bullet points):** Specific, data-driven observations about significant variances or trends in revenue components (GPR, Vacancy, Other Income), operating expenses (major categories), and overall NOI. Quantify insights where possible (e.g., "Vacancy loss decreased by X%, contributing Y to NOI improvement").
    3.  **Actionable Recommendations (3-5 bullet points):** Concrete suggestions based *directly* on the observed variances to improve NOI. Focus on areas like reducing specific expenses, improving rent collection/reducing vacancy, increasing other income, or investigating budget variances.

    Format your response clearly with the numbered sections and bullet points as requested. Be professional and objective.
    """

    logger.info(f"Sending detailed prompt to GPT API (length: {len(prompt)} chars)...")
    # logger.debug(f"GPT Prompt:\n{prompt}") # Be cautious logging full prompts with data

    try:
        # Call OpenAI API
        response = client.chat.completions.create(
            model="gpt-4", # Or "gpt-4-turbo"
            messages=[
                {"role": "system", "content": "You are a senior real estate financial analyst specializing in detailed NOI variance analysis and reporting."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5, # Slightly higher temp for more nuanced language
            max_tokens=1200 # Allow more tokens for detailed analysis
        )

        # Log the response
        response_content = response.choices[0].message.content
        logger.info(f"Received response from GPT API (length: {len(response_content)} chars).")
        # logger.debug(f"GPT Raw Response:\n{response_content}")

        # Parse the content into our expected format (using existing parser, should handle sections)
        insights = parse_gpt_response(response_content) # Reuse existing parser

        return insights
    except Exception as e:
        logger.error(f"Error generating insights with GPT: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        return {
            "summary": f"Error generating insights: {str(e)}. Please check logs.",
            "performance": ["Unable to generate performance insights due to an error."],
            "recommendations": ["Please try again or contact support."]
        }

def format_detailed_comparison_results_for_prompt(comparison_results: Dict[str, Any]) -> str:
    """
    Formats the DETAILED comparison results into a string for the GPT prompt.

    Args:
        comparison_results: Results from calculate_noi_comparisons() using detailed data.

    Returns:
        Formatted string with detailed comparison results.
    """
    formatted_text = ""
    current = comparison_results.get("current")

    def format_value(value):
        """Formats numbers, handling None."""
        return f"${value:,.2f}" if isinstance(value, (int, float)) else "N/A"

    def format_change(change, percentage):
        """Formats change and percentage."""
        change_str = f"{format_value(change)}"
        percent_str = f"{percentage:.1f}%" if isinstance(percentage, (int, float)) else "N/A"
        indicator = "+" if change > 0 else "" if change == 0 else "" # Show sign only if non-zero
        return f"{indicator}{change_str} ({percent_str})"

    # --- Current Period ---
    if current:
        formatted_text += "CURRENT PERIOD DATA:\n"
        formatted_text += f"- Gross Potential Rent (GPR): {format_value(current.get('gpr'))}\n"
        formatted_text += f"- Vacancy & Credit Loss: {format_value(current.get('vacancy_loss'))}\n"
        formatted_text += f"- Other Income: {format_value(current.get('other_income'))}\n"
        formatted_text += f"- Effective Gross Income (EGI): {format_value(current.get('egi'))}\n"
        formatted_text += f"- Total Operating Expenses (OpEx): {format_value(current.get('opex'))}\n"
        formatted_text += f"- Net Operating Income (NOI): {format_value(current.get('noi'))}\n\n"

    # --- Actual vs. Budget ---
    avb = comparison_results.get("actual_vs_budget")
    if avb and current:
        formatted_text += "ACTUAL VS BUDGET COMPARISON:\n"
        formatted_text += f"Metric          | Actual         | Budget         | Variance ($)   | Variance (%)\n"
        formatted_text += f"----------------|----------------|----------------|----------------|--------------\n"
        for key, name in [("gpr", "GPR"), ("vacancy_loss", "Vacancy Loss"), ("other_income", "Other Income"),
                          ("egi", "EGI"), ("opex", "Total OpEx"), ("noi", "NOI")]:
            actual = current.get(key, 0.0)
            budget = avb.get(f"{key}_budget", 0.0)
            variance = avb.get(f"{key}_variance", 0.0)
            percent_var = avb.get(f"{key}_percent_variance", 0.0)
            # Note: Higher vacancy/opex variance is usually unfavorable
            formatted_text += f"{name:<15} | {format_value(actual):<14} | {format_value(budget):<14} | {format_value(variance):<14} | {percent_var:>10.1f}%\n"
        formatted_text += "\n"

    # --- Year-over-Year ---
    yoy = comparison_results.get("year_vs_year")
    if yoy and current:
        formatted_text += "YEAR-OVER-YEAR COMPARISON:\n"
        formatted_text += f"Metric          | Current Year   | Prior Year     | Change ($)     | Change (%)\n"
        formatted_text += f"----------------|----------------|----------------|----------------|--------------\n"
        for key, name in [("gpr", "GPR"), ("vacancy_loss", "Vacancy Loss"), ("other_income", "Other Income"),
                          ("egi", "EGI"), ("opex", "Total OpEx"), ("noi", "NOI")]:
            actual = current.get(key, 0.0)
            prior = yoy.get(f"{key}_prior_year", 0.0)
            change = yoy.get(f"{key}_change", 0.0)
            percent_change = yoy.get(f"{key}_percent_change", 0.0)
            formatted_text += f"{name:<15} | {format_value(actual):<14} | {format_value(prior):<14} | {format_value(change):<14} | {percent_change:>10.1f}%\n"
        formatted_text += "\n"

    # --- Month-over-Month ---
    mom = comparison_results.get("month_vs_prior")
    if mom and current:
        formatted_text += "MONTH-OVER-MONTH COMPARISON:\n"
        formatted_text += f"Metric          | Current Month  | Prior Month    | Change ($)     | Change (%)\n"
        formatted_text += f"----------------|----------------|----------------|----------------|--------------\n"
        for key, name in [("gpr", "GPR"), ("vacancy_loss", "Vacancy Loss"), ("other_income", "Other Income"),
                          ("egi", "EGI"), ("opex", "Total OpEx"), ("noi", "NOI")]:
            actual = current.get(key, 0.0)
            prior = mom.get(f"{key}_prior", 0.0)
            change = mom.get(f"{key}_change", 0.0)
            percent_change = mom.get(f"{key}_percent_change", 0.0)
            formatted_text += f"{name:<15} | {format_value(actual):<14} | {format_value(prior):<14} | {format_value(change):<14} | {percent_change:>10.1f}%\n"
        formatted_text += "\n"

    return formatted_text.strip()

def parse_gpt_response(response_text: str) -> Dict[str, Any]:
    """
    Parse the GPT response into a structured format.

    Args:
        response_text: Raw text response from GPT.

    Returns:
        Dictionary with parsed insights.
    """
    insights = {
        "summary": "",
        "performance": [],
        "recommendations": []
    }

    # Simple but effective parsing approach
    sections = {
        "summary": None,
        "performance": None,
        "recommendations": None
    }
    
    # First pass: identify section boundaries
    lines = response_text.split('\n')
    for i, line in enumerate(lines):
        line = line.strip()
        if not line:
            continue
        
        # Look for executive summary section
        if re.search(r'(?i)^\s*(?:\d+[\.\)]\s*)?executive\s+summary', line) or re.search(r'(?i)^\s*(?:\d+[\.\)]\s*)?summary\s*:', line):
            sections["summary"] = i
        # Look for performance insights section
        elif re.search(r'(?i)^\s*(?:\d+[\.\)]\s*)?key\s+performance', line) or re.search(r'(?i)^\s*(?:\d+[\.\)]\s*)?performance', line):
            sections["performance"] = i
        # Look for recommendations section
        elif re.search(r'(?i)^\s*(?:\d+[\.\)]\s*)?recommendations', line) or re.search(r'(?i)^\s*(?:\d+[\.\)]\s*)?action', line):
            sections["recommendations"] = i
    
    # If we couldn't find any sections, try to infer them
    if sections["summary"] is None and sections["performance"] is None and sections["recommendations"] is None:
        # Assume first paragraph is summary
        sections["summary"] = 0
        
        # Look for bullet points to identify other sections
        for i, line in enumerate(lines):
            if i > 0 and (line.strip().startswith('-') or line.strip().startswith('•')):
                if sections["performance"] is None:
                    sections["performance"] = i
                elif sections["recommendations"] is None:
                    sections["recommendations"] = i
                    break
    
    # Second pass: extract content from each section
    section_ranges = []
    section_keys = ["summary", "performance", "recommendations"]
    
    # Create section ranges
    for i, key in enumerate(section_keys):
        if sections[key] is not None:
            start = sections[key]
            end = None
            
            # Find the end of this section (start of next section or end of text)
            for next_key in section_keys[i+1:]:
                if sections[next_key] is not None:
                    end = sections[next_key]
                    break
            
            section_ranges.append((key, start, end))
    
    # Process each section
    for section, start, end in section_ranges:
        section_lines = lines[start:end] if end else lines[start:]
        
        # Skip the header line for each section
        if section_lines and any(marker in section_lines[0].lower() for marker in ["summary", "performance", "recommendations", "action"]):
            section_lines = section_lines[1:]
        
        # Process based on section type
        if section == "summary":
            # Join all lines for summary
            insights["summary"] = " ".join([line.strip() for line in section_lines if line.strip()])
        else:
            # Process bullet points for performance and recommendations
            current_point = ""
            for line in section_lines:
                line = line.strip()
                if not line:
                    continue
                
                # Check if this is a new bullet point
                if line.startswith('-') or line.startswith('•') or (line[0].isdigit() and len(line) > 1 and line[1] in ['.', ')']):
                    # Save previous point if exists
                    if current_point:
                        insights[section].append(current_point)
                    
                    # Start new point (remove bullet)
                    current_point = line.lstrip('-•0123456789.) ')
                else:
                    # Continue previous point
                    if current_point:
                        current_point += " " + line
            
            # Add the last point if exists
            if current_point:
                insights[section].append(current_point)
    
    # If we still don't have a summary, use the first paragraph
    if not insights["summary"]:
        paragraphs = [p for p in response_text.split('\n\n') if p.strip()]
        if paragraphs:
            insights["summary"] = paragraphs[0].strip()
    
    # Log the parsed insights for debugging
    logger.info(f"Parsed insights: summary={bool(insights['summary'])}, performance={len(insights['performance'])}, recommendations={len(insights['recommendations'])}")
    
    return insights
